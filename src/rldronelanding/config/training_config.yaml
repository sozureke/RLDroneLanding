algorithm: ppo
total_timesteps: 200_000
learning_rate: 0.0003
gamma: 0.99
batch_size: 64
n_steps: 2048
ent_coef: 0.0
clip_range: 0.2
gae_lambda: 0.95
policy: "MlpPolicy"
log_dir: "logs/ppo/"
model_save_path: "models/ppo_drone"
render: false
enable_wind: true
enable_platform_motion: true
