algorithm: ppo
total_timesteps: 5_000_000
learning_rate: 0.0001
gamma: 0.99
batch_size: 128
n_steps: 2048
ent_coef: 0.02
clip_range: 0.2
gae_lambda: 0.95
policy: "MlpPolicy"
log_dir: "logs/ppo/"
model_save_path: "models/ppo_drone"
render: false
enable_wind: false
enable_platform_motion: false
